# About sth

## 文件上传
### 目前的文件上传流程是:
1. 上传文件到后端
2. 后端拿到文件,重命名, 上传到 Google Could Storage, 拿到文件的 URL
3. 后端用 URL 调用 Google Cloud Vision API, 拿到文件的文字内容
4. 后端将文件的文字内容和文件的 URL 存入数据库

### 优化思路
将服务部署到境外服务器, 上传会快一些

--- 

## 与 chatgpt 的交互
### 目前的交互方式是:

用识别出的 PDF 文档内容作为输入, 调用 chatgpt 的 API, 得到回复. 后来发现, 文档内容太长,
超出了 openai 官方的限制 .chatgpt 会报错, 所以只取了前 1500 个字符作为输入.

即便如此, 多轮对话之后, 随着 history_list 内容不断增加, 还是会超出限制.

此外, 不能给用户指出某个问题的相关内容在文章的第几页

### 优化思路
#### 一
1. 只在开始对话时发送一次较多的文档内容, 询问 chatgpt 该文档的主题是什么, 得到主题.
2. 之后的对话, 用得到的一小段主题作为输入, 代替原本在每次会话时携带的正文内容. 询问 chatgpt
   该主题的相关问题, 得到相关回答.

目前能想到, 此办法需要对 与 chatgpt 的交互 进行许多改进, 需要多次试验各种对话方式. 例如:

```
backend: 我将发给你一篇文章，请你告诉我这篇文章的主要信息是什么？
chatgpt: 这篇文章主题是 xxx, 作者是 xxx, 发表于 xxxx 年 xx 月 xx 日, 主要讲了 xxx, 
         采用 xxx 的方式.... 得到了 xxx 的结论.
          
----- 拿到主题, 结束本次对话  ---

backend: 我有一篇关于 xxx 的文章, 文章的主要内容是: 作者是 xxx, 发表于 xxxx 年 xx 月 xx 日, 主要讲了 xxx, 
         采用 xxx 的方式....得到了 xxx 的结论.
         请你记住这些信息, 然后我要询问你关于这篇文章的一些问题,接下来我们的对话都必须围绕这个
         文章的内容进行

...
     

```

#### 二

   在后台先对用户的问题进行预处理, 将用户的问题语句 与 文档内容进行匹配, 找到相关的内容, 
   大概在第几页, 然后将文档的主题和用户的问题发给 chatgpt, 询问 chatgpt 该问题的相关回答.
   既能告诉用户问题的答案,也能告诉他在第几页

---

## 后台有待改进的
1. 使用 redis 缓存对话历史记录
2. 文件上传流程很慢, 最好能把上传和识别的进度返回给前端
